# CASA0014: Connected Environments 24/25_LumoStick
<img src="./images/cl.png" alt="cl" style="width: 100%; height: auto;">

<!--<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe 
    src="https://www.youtube.com/embed/dQw4w9WgXcQ" 
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
    frameborder="0" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
    allowfullscreen>
  </iframe>
</div>
-->



## ðŸŒŸ Project Overview
<!-- Lumostickæ˜¯ä¸€æ¬¾ç”± ESP32 å’Œ MPU6050 é©±åŠ¨çš„æ‰‹åŠ¿æŽ§åˆ¶æ£’ï¼Œèƒ½å¤Ÿè§¦å‘ Neopixel çŽ¯å½¢çŸ©é˜µ Chrono Lumina ä¸Šçš„æ•ˆæžœã€‚é™¤äº†æ“æŽ§LEDç¯æœ¬èº«ä¹‹å¤–ï¼ŒLumostickçš„é¡¹ç›®è¿˜å¸®åŠ©æˆ‘å¼€å§‹å­¦ä¹ ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥å¤„ç†æ•°æ®ä»¥åŠè¿›ä¸€æ­¥æŽ¢ç´¢äººå’ŒIoTç³»ç»Ÿçš„äº¤äº’å…³ç³»-->



**Lumostick** is a gesture-controlled wand powered by ESP32 and MPU6050, capable of triggering effects on Chrono Lumina (https://github.com/ucl-casa-ce/casa0014/tree/271e6a09e3415dd92d1bf312cf6354610c04c1a2/chronoLumina), a matrix of 53 Neopixel rings. Beyond  manipulating the LED itself, this project helped me start learning to use machine learning to process data and further explore the interaction between people and IoT systems.

---
<!-- ðŸŽ¯ çµæ„Ÿä¸Žæ„¿æ™¯
é‡æ–°æ€è€ƒäº¤äº’æ¨¡å¼
ä¼ ç»Ÿç•Œé¢ï¼šæ‰‹æœºã€é”®ç›˜å’Œè§¦æ‘¸å±ä¸»å¯¼ç€ç‰©è”ç½‘äº¤äº’ï¼Œä½†åœ¨ç›´è§‚ã€æ²‰æµ¸å¼å’Œå…æåº”ç”¨æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
æ‰‹åŠ¿æŽ§åˆ¶ï¼šåˆ©ç”¨è‡ªç„¶çš„äººä½“åŠ¨ä½œä¸ŽæŠ€æœ¯äº’åŠ¨å¯ä»¥åˆ›é€ æ›´ç›´è§‚ã€æ›´æ˜“èŽ·å¾—çš„ä½“éªŒã€‚
æœªæ¥çš„åº”ç”¨
è™šæ‹ŸçŽ°å®ž (VR)ï¼šåŸºäºŽæ‰‹åŠ¿çš„æŽ§åˆ¶å¢žå¼ºäº†æ²‰æµ¸æ„Ÿå’Œäº¤äº’æ€§ï¼Œä»Žè€Œæ— éœ€åœ¨ VR/AR çŽ¯å¢ƒä¸­ä½¿ç”¨ç‰©ç†æŽ§åˆ¶å™¨ã€‚
è¾…åŠ©æŠ€æœ¯ï¼šæ‰‹åŠ¿è¯†åˆ«å¯ä»¥ä¸ºæ®‹éšœäººå£«æä¾›ä¾¿æ·çš„æ–¹å¼æ¥æŽ§åˆ¶è®¾å¤‡ï¼Œä»Žæ™ºèƒ½å®¶å±…ç³»ç»Ÿåˆ°ç§»åŠ¨è¾…åŠ©è®¾å¤‡ã€‚
äº’åŠ¨è‰ºæœ¯ä¸Žè¡¨æ¼”ï¼šè‰ºæœ¯å®¶å’Œè¡¨æ¼”è€…å¯ä»¥ä½¿ç”¨åŸºäºŽæ‰‹åŠ¿çš„å·¥å…·æ¥åˆ›å»ºåŠ¨æ€å’Œå“åº”çš„çŽ¯å¢ƒã€‚
æ—¥å¸¸ç‰©è”ç½‘è®¾å¤‡ï¼šä»Žç…§æ˜Žåˆ°æ™ºèƒ½å®¶ç”µï¼Œæ‰‹åŠ¿æŽ§åˆ¶æä¾›äº†ä¸€ç§ä¸Žè¿žæŽ¥è®¾å¤‡äº¤äº’çš„æ— ç¼ä¸”å¼•äººå…¥èƒœçš„æ–¹å¼ã€‚
æ›´å¹¿æ³›çš„å½±å“
Lumostick çš„æ–¹æ³•å±•ç¤ºäº†ç‰©è”ç½‘å’Œäººå·¥æ™ºèƒ½åœ¨é‡æ–°å®šä¹‰äººç±»ä¸ŽæŠ€æœ¯äº’åŠ¨æ–¹å¼æ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡æŽ¢ç´¢æ›¿ä»£ç•Œé¢ï¼Œå®ƒä¸ºå„ä¸ªé¢†åŸŸçš„åŒ…å®¹æ€§å’Œæ²‰æµ¸å¼åˆ›æ–°å¼€è¾Ÿäº†å¯èƒ½æ€§ã€‚
-->

## ðŸŽ¯ Inspiration and Vision
<!--å½“æˆ‘é¢å¯¹Chrono Luminaå¹¶æ€è€ƒåº”è¯¥å¦‚ä½•æŽ§åˆ¶å®ƒçš„æ—¶å€™ï¼Œæˆ‘æœ¬èƒ½åœ°ä¼¸å‡ºåŒæ‰‹åœ¨ç©ºä¸­æ¯”åˆ’ï¼Œåƒæ˜¯æƒ³è¦æŒ‡æŒ¥è¿™ä¸ªå…‰çš„â€œäº¤å“ä¹å›¢â€æ¼”å¥ã€‚æˆ‘è¿›ä¸€æ­¥è”æƒ³åˆ°ç³»åˆ—ç”µå½±â€˜å“ˆåˆ©æ³¢ç‰¹â€™ä¸­å·«å¸ˆä»¬ç”¨é­”æ–æ“æŽ§ç‰©ä½“çš„åœºæ™¯ï¼Œè”ç½‘è®¾å¤‡ä¹‹é—´çš„å…³ç³»ä¸æ­£åƒè¿™ç§æ— å½¢çš„é­”åŠ›è¿žæŽ¥å—ï¼Ÿè€Œäººç±»ä½œä¸ºIoTç³»ç»Ÿçš„ä¸€çŽ¯ï¼Œèƒ½ä¸èƒ½æŽŒæ¡å·«å¸ˆé‚£èˆ¬çš„æ“æŽ§åŠ›å‘¢ï¼Ÿ-->
**Origin** When I faced the Chrono Lumina and thought about how I should control it, I instinctively stretched out my hands in the air, as if I wanted to conduct the symphony orchestra of light. I further think of the scenes in the movie series 'Harry Potter' where wizards manipulate objects with wands. Isn't the relationship between connected devices just like this invisible magical connection? And as a part of the IoT system, can humans master the control power of wizards?

### Rethinking Interaction Modes
1. **Traditional Interfaces**: Phones, keyboards, and touchscreens dominate IoT interactions but have limitations in intuitive, immersive, and hands-free applications.
2. **Gesture Control**: Harnessing natural human motions to interact with technology can create more intuitive and accessible experiences.


<table style="width: 100%; text-align: center; border-spacing: 20px;">
  <tr>
    <td>
      <img src="./images/image1.jpg" alt="Virtual Reality" style="width: 100%; height: auto; border-radius: 5px;">
      <p>Virtual Reality</p>
    </td>
    <td>
      <img src="./images/image2.jpg" alt="Assistive Technology" style="width: 100%; height: auto; border-radius: 5px;">
      <p>Assistive Technology</p>
    </td>
  </tr>
  <tr>
    <td>
      <img src="./images/image3.jpg" alt="Interactive Art and Performance" style="width: 100%; height: auto; border-radius: 5px;">
      <p>Interactive Art and Performance</p>
    </td>
    <td>
      <img src="./images/image4.jpg" alt="Smart Home Devices" style="width: 100%; height: auto; border-radius: 5px;">
      <p>Smart Home Devices</p>
    </td>
  </tr>
</table>


### Broader Impact
Lumostick's approach showcases the potential of IoT and AI in redefining how humans interact with technology. By exploring alternative interfaces, it opens up possibilities for inclusive and immersive innovations in various fields.

---

## ðŸš€ Features of Lumostick
- **Motion Recognition**: Employs TensorFlow Lite for precise pattern recognition.
- **Dynamic Visual Feedback**: Displays unique lighting effects on Chrono Lumina.
- **Wireless Control**: Operates through ESP32 for seamless and untethered usage.
- **Customizable Framework**: Easily expandable to recognize additional gestures and control other devices.


---

## ðŸš€ Design

<img src="./images/wand_design.jpg" alt="Wand Design" style="width: 100%; height: auto;">
<img src="./images/wand_protype.jpg" alt="Wand Design" style="width: 100%; height: auto;">
<img src="./images/wand_protype2.jpg" alt="Wand Design" style="width: 100%; height: auto;">
<img src="./images/modeling.png" alt="Wand Design" style="width: 100%; height: auto;">
<img src="./images/wand.png" alt="Wand Design" style="width: 100%; height: auto;">
  
---

## ðŸ› ï¸ Technical Overview

### System Workflow
```plaintext
[Gesture Input] -> [MPU6050 Sensor] -> [ESP32 Processing via TensorFlow Lite] -> [Neopixel Control] -> [Visual Output on Chrono Lumina]
```

### Key Technologies
- **Chrono Lumina**: Neopixel ring matrix for dynamic light displays.
- **ESP32**: The central processing unit, handling gesture recognition and device control.
- **MPU6050**: A six-axis motion sensor capturing real-time gestures.
```cpp
// Fast motion detection
if (absX > absY && absX > absZ && absX > fastMotionThreshold) {
    primaryDirection = accXg > 0 ? "X" : "-X";
    currentMagnitude = absX;
} else if (absY > absX && absY > absZ && absY > fastMotionThreshold) {
    primaryDirection = accYg > 0 ? "Y" : "-Y";
    currentMagnitude = absY;
} else if (absZ > absX && absZ > absY && absZ > fastMotionThreshold) {
    primaryDirection = accZg > 0 ? "Z" : "-Z";
    currentMagnitude = absZ;
}

// Detect return-to-origin motion
if (!primaryDirection.isEmpty() && !lastDirection.isEmpty() && 
    primaryDirection == inverseDirection(lastDirection) &&
    fabs(currentMagnitude - lastMagnitude) < returnTolerance) {
    Serial.println("Return-to-origin motion detected, recalibrating offsets");
    calibrateOffsetsFast();
    lastDirection = ""; // Clear last motion
    lastMagnitude = 0;
    lastNoMovementTime = currentTime; // Reset no-motion timer
}
// Output fast motion result
else if (!primaryDirection.isEmpty() && (currentTime - lastMovementTime > movementCooldown)) {
    Serial.println(primaryDirection + " direction fast motion detected");
    lastDirection = primaryDirection; // Save current motion direction
    lastMagnitude = currentMagnitude; // Save current motion magnitude
    calibrateOffsetsFast(); // Recalibrate offsets after fast motion
    lastMovementTime = currentTime; // Update last motion time
    lastNoMovementTime = currentTime; // Reset no-motion timer
}
// Detect slow motion and recalibrate offsets
else if (primaryDirection.isEmpty() && 
         (absX > slowMotionThreshold || absY > slowMotionThreshold || absZ > slowMotionThreshold)) {
    calibrateOffsetsFast(); // Recalibrate offsets during slow motion
    lastNoMovementTime = currentTime; // Reset no-motion timer
}
// No motion detected
else if (primaryDirection.isEmpty() && (currentTime - lastNoMovementTime > noMovementInterval)) {
    Serial.println("No motion detected");
    lastNoMovementTime = currentTime;
}

delay(200); // Delay for better observation of data
```

The most difficult part of using the MPU6050 is to identify the threshold and excessive hand movements, such as when I wave the wand, I will habitually withdraw it, which will be detected by the sensor as two movements, so I introduced a homing mechanism.

- **TensorFlow Lite**: Machine learning library for on-device gesture pattern recognition.
<img src="./images/images.png" alt="Wand Design" style="width: 100%; height: auto;">

<table>
  <tr>
    <td><img src="./images/gif_slope.gif" alt="GIF 1" style="width: 300px; height: auto;"></td>
    <td><img src="./images/gif_wing.gif" alt="GIF 2" style="width: 300px; height: auto;"></td>
    <td><img src="./images/gif_ring.gif" alt="GIF 3" style="width: 300px; height: auto;"></td>
  </tr>
</table>






### Open-Source Ecosystem
I got the three models they trained from tensorflowlite, after all the initial test identification, the next step is to implement them on Chrono Lumina.

Thanks for the open source model provided by the Tensorflow team. In the next step, I will follow the tutorials provided by Tensorflow to train my own model, which may be a love, and move towards the further goal!

---

## ðŸ”® Exploring Gesture-Based IoT Interaction

### Why Gesture Control?
1. **Natural and Intuitive**: Gestures align closely with human behavior, enabling users to interact with technology effortlessly.
2. **Hands-Free Operation**: Ideal for scenarios where touch-based interfaces are impractical.
3. **Enhanced Immersion**: Particularly valuable in VR/AR applications, where physical controllers may disrupt the user experience.

### Challenges and Opportunities
1. **Challenges**:
   - Ensuring accuracy and reliability in gesture recognition.
   - Developing adaptable systems for diverse user needs.
2. **Opportunities**:
   - Bridging the gap between humans and technology for inclusivity and accessibility.
   - Creating new interaction paradigms for future IoT and VR devices.

---
## ðŸ“š References

- TensorFlow Lite: [https://www.tensorflow.org/lite](https://www.tensorflow.org/lite)
- TensorFlow (ESP32 Version):[https://github.com/petewarden/magic_wand]
- ESP32 Documentation: [https://espressif.com/](https://espressif.com/)
- Chrono Lumina (Neopixel Matrix): [https://github.com/ucl-casa-ce/casa0014/tree/271e6a09e3415dd92d1bf312cf6354610c04c1a2/chronoLumina]

---

## ðŸ™Œ Digital Twin Project
<!-- Lumostickæ˜¯ä¸€æ¬¾ç”± ESP32 å’Œ MPU6050 é©±åŠ¨çš„æ‰‹åŠ¿æŽ§åˆ¶æ£’ï¼Œèƒ½å¤Ÿè§¦å‘ Neopixel çŽ¯å½¢çŸ©é˜µ Chrono Lumina ä¸Šçš„æ•ˆæžœã€‚é™¤äº†æ“æŽ§LEDç¯æœ¬èº«ä¹‹å¤–ï¼ŒLumostickçš„é¡¹ç›®è¿˜å¸®åŠ©æˆ‘å¼€å§‹å­¦ä¹ ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥å¤„ç†æ•°æ®ä»¥åŠè¿›ä¸€æ­¥æŽ¢ç´¢äººå’ŒIoTç³»ç»Ÿçš„äº¤äº’å…³ç³»-->

If time permits, I am planning to build a digital twin for Chrono Lumina, which will be beneficial for the testing of lighting effects and sustainable use in the future. Welcome to join, you can see my model building and lighting grouping for Chrono Lumina in my library.

---

## ðŸ“š Reflection

- The recognition accuracy of the MPU6050 is not high and requires more training.
- If I want to approach intelligent control, you need to reduce the size of the hardware and increase the multi-dimensional control, such as sound.

